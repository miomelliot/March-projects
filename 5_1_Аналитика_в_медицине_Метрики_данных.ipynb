{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miomelliot/March-projects/blob/main/5_1_%D0%90%D0%BD%D0%B0%D0%BB%D0%B8%D1%82%D0%B8%D0%BA%D0%B0_%D0%B2_%D0%BC%D0%B5%D0%B4%D0%B8%D1%86%D0%B8%D0%BD%D0%B5_%D0%9C%D0%B5%D1%82%D1%80%D0%B8%D0%BA%D0%B8_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d00fea5b",
      "metadata": {
        "id": "d00fea5b"
      },
      "outputs": [],
      "source": [
        "!pip -q install pyspark seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3947a2d5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "3947a2d5",
        "outputId": "5ee6841e-1dbd-44b8-eaf4-8781e3ff24c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7a5c68085210>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://a4e9ac44539a:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>IrisLR</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"IrisLR\").getOrCreate()\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "22f4f7cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22f4f7cb",
        "outputId": "83a434ed-5631-4201-8e8f-0d0c666a396f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset ready at /content/iris.csv\n"
          ]
        }
      ],
      "source": [
        "import os, urllib.request, shutil\n",
        "iris_path = \"/content/iris.csv\"\n",
        "if not os.path.exists(iris_path):\n",
        "    url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv\"\n",
        "    with urllib.request.urlopen(url) as response, open(iris_path, 'wb') as out_file:\n",
        "        shutil.copyfileobj(response, out_file)\n",
        "print(\"Dataset ready at\", iris_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d91d85cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d91d85cb",
        "outputId": "5136a5b5-193d-447e-98fa-d53766663a1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+------------+-----------+-------+\n",
            "|sepal_length|sepal_width|petal_length|petal_width|species|\n",
            "+------------+-----------+------------+-----------+-------+\n",
            "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
            "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
            "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
            "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
            "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
            "+------------+-----------+------------+-----------+-------+\n",
            "only showing top 5 rows\n",
            "\n",
            "root\n",
            " |-- sepal_length: double (nullable = true)\n",
            " |-- sepal_width: double (nullable = true)\n",
            " |-- petal_length: double (nullable = true)\n",
            " |-- petal_width: double (nullable = true)\n",
            " |-- species: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "iris_df = spark.read.csv(\"/content/iris.csv\", header=True, inferSchema=True)\n",
        "iris_df.show(5)\n",
        "iris_df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7dc3a713",
      "metadata": {
        "id": "7dc3a713"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "label_indexer = StringIndexer(inputCol=\"species\", outputCol=\"label\")\n",
        "\n",
        "feature_cols = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
        "\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=100, regParam=0.0, elasticNetParam=0.0, family=\"multinomial\")\n",
        "\n",
        "pipeline = Pipeline(stages=[label_indexer, assembler, lr])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d7935703",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7935703",
        "outputId": "662addbe-6783-4af4-969a-440c75083f4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 126, Test set size: 24\n"
          ]
        }
      ],
      "source": [
        "train_df, test_df = iris_df.randomSplit([0.8, 0.2], seed=42)\n",
        "print(f\"Training set size: {train_df.count()}, Test set size: {test_df.count()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b5fa4f7f",
      "metadata": {
        "id": "b5fa4f7f"
      },
      "outputs": [],
      "source": [
        "model = pipeline.fit(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d5e81d74",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5e81d74",
        "outputId": "c5560066-554b-472b-b81f-41b5721cccf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy: 0.9841\n",
            "Test accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "def evaluate(df, split_name):\n",
        "    preds = model.transform(df)\n",
        "    evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "    acc = evaluator.evaluate(preds)\n",
        "    print(f\"{split_name} accuracy: {acc:.4f}\")\n",
        "    return acc\n",
        "\n",
        "train_acc = evaluate(train_df, \"Train\")\n",
        "test_acc = evaluate(test_df, \"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e91b3b32",
      "metadata": {
        "id": "e91b3b32"
      },
      "outputs": [],
      "source": [
        "spark.stop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}